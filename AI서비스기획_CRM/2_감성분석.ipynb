{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_감성분석.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NRU4um4C97xH"},"source":["# 사전을 이용한 감성분석"]},{"cell_type":"code","metadata":{"id":"U-C4fLU196mO"},"source":["#from google.colab import auth\n","#auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AfWgddcj-Fzf"},"source":["# 형태소분석기 관련 설치\n","!apt-get update\n","!apt-get install g++ openjdk-8-jdk\n","\n","!pip install JPype1\n","!pip install rhinoMorph"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zC1IjIgg-HAK"},"source":["# 경로 변경\n","%cd /content/gdrive/My\\ Drive/pytest/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_0US14G-IUp"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QorRG2yCF5Jx"},"source":["# 데이터 로딩\n","def read_data(filename, encoding='cp949'):                # 읽기 함수 정의\n","  with open(filename, 'r', encoding=encoding) as f:\n","    data = [line.split('\\t') for line in f.read().splitlines()]\n","    data = data[1:]                 # txt 파일의 헤더(id document label)는 제외하기\n","  return data\n","\n","def write_data(data, filename, encoding='cp949'):         # 쓰기 함수도 정의\n","  with open(filename, 'w', encoding=encoding) as f:\n","    f.write(data)\n","\n","#data = read_data('/content/gdrive/My Drive/pytest/ratings.txt', encoding='cp949')\n","data = read_data('ratings.txt', encoding='cp949')         # 전체파일은 ratings.txt "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-qxMyR_m0tE"},"source":["print(len(data))\n","print(data[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKl2hToAGC5p"},"source":["# 전체 데이터 형태소 분석\n","import rhinoMorph\n","rn = rhinoMorph.startRhino()\n","\n","morphed_data = ''\n","for data_each in data:\n","  morphed_data_each = rhinoMorph.onlyMorph_list(rn, data_each[1], pos=['NNG', 'NNP', 'VV', 'VA', 'XR', 'IC', 'MM', 'MAG', 'MAJ'])\n","  joined_data_each = ' '.join(morphed_data_each)\t\t\t        # 문자열을 하나로 연결\n","  if joined_data_each:                                      \t# 내용이 있는 경우만 저장하게 함\n","    morphed_data += data_each[0]+\"\\t\"+joined_data_each+\"\\t\"+data_each[2]+\"\\n\"\n","    \n","# 형태소 분석된 파일 저장\n","write_data(morphed_data, 'ratings_morphed.txt', encoding='cp949')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVJR21gV-J7-"},"source":["# 형태소 분석된 데이터 로딩\n","data = read_data('ratings_morphed.txt', encoding='cp949')\n","\n","print(len(data))   \n","print(len(data[0])) \n","print(data[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0eXWQPQ-LPC"},"source":["# 분석된 내용을 id, text, label로 분리\n","data_id = [line[0] for line in data]       \t\t# 데이터 id\n","data_text = [line[1] for line in data]     \t\t# 데이터 본문\n","data_senti = [line[2] for line in data]    \t\t# 데이터 긍부정 부분"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQ-TUtnjJc24"},"source":["# 감정사전 읽기\n","positive = read_data('positive.txt')\t\t      # 긍정 감정사전 읽기\n","negative = read_data('negative.txt')\t\t      # 부정 감정사전 읽기\n","\n","print(\"positive:\", positive)\n","print(\"negatvie:\", negative)\n","                     \n","pos_found = []                                # 각 문장에서 발견될 긍정어의 개수 \n","neg_found = []                                # 각 문장에서 발견될 부정어의 개수 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tbd1U7JS-MeQ"},"source":["# 감정단어 파악\n","def cntWordInLine(data, senti):\n","  senti_found = []\n","  for onedata in data:\n","    oneline_word = onedata.split(' ')       # 한 줄의 데이터를 공백 단위로 분리하여 리스트로 저장\n","    senti_temp = 0\n","    for sentiword in senti:      \n","      if sentiword[0] in oneline_word:      # posword[0] 하여 리스트를 문자열로 추출\n","        senti_temp += 1                     # 현재의 감정단어와 일치하면 숫자를 하나 올려 줌 (중복은 계산 안 함)\n","    senti_found.append(senti_temp)          # 현재의 줄에서 찾은 감성단어의 숫자를 해당 위치에 저장\n","  return senti_found\n","      \n","      \n","data_senti_poscnt = cntWordInLine(data_text, positive)      # 발견된 긍정 단어의 숫자 파악\n","data_senti_negcnt = cntWordInLine(data_text, negative)      # 발견된 부정 단어의 숫자 파악\n","\n","print(data_senti_poscnt[:20])\n","print(data_senti_negcnt[:20])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Kp3ebhC-Nxv"},"source":["# 감정점수 계산\n","# Pandas 데이터프레임으로 저장\n","import pandas as pd\n","newdata = pd.DataFrame({'id':data_id, 'text':data_text, 'original':data_senti, \n","                        'pos':data_senti_poscnt, 'neg':data_senti_negcnt})\n","senti_score = newdata['pos'] - newdata['neg']      # 긍정개수에서 부정개수를 뺌\n","newdata['senti_score'] = senti_score               # 그 수를 senti_score 컬럼에 저장 \n","\n","newdata.loc[newdata.senti_score > 0, 'new'] = 1    # 새로운 긍부정 기호\n","newdata.loc[newdata.senti_score <= 0, 'new'] = 0   # 새로운 긍부정 기호\n","\n","# 처음에 기록된 긍부정과 새로 계산된 긍부정이 같은지 여부를 matched 컬럼에 저장\n","# original 컬럼은 문자로 되어 있으므로 숫자로 변환 뒤 비교 \n","newdata.loc[pd.to_numeric(newdata.original) == newdata.new, 'matched'] = 'True'\n","newdata.loc[pd.to_numeric(newdata.original) != newdata.new, 'matched'] = 'False'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mEBwHH7Tt-Xw"},"source":["newdata.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxU2JM5u-O9s"},"source":["score = newdata.matched.str.count('True').sum() / (newdata.matched.str.count('True').sum() \n","                                 + newdata.matched.str.count('False').sum()) * 100\n","                                 \n","print(score)\n","\n","newdata.to_csv('newfile.csv', sep=',', encoding='cp949', index=False) \t# csv 저장\n","newdata.to_csv('newfile2.txt', sep='\\t', encoding='cp949', index=False) \t# 또는 txt 저장"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"niR68yLq-Qsv"},"source":["# 시그모이드 점수 계산\n","import math\n","def sigmoid(x):\n","  return 1 / (1 + math.exp(-x))\n","\n","newdata['sigmoid'] = newdata.senti_score.apply(sigmoid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73hv7WuNv8mk"},"source":["newdata.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8stRR50M-TZl"},"source":["# 머신러닝을 이용한 감성분석 "]},{"cell_type":"code","metadata":{"id":"FDEOAtfN-Vo0"},"source":["# 형태분석된 데이터 로딩\n","def read_data(filename, encoding='cp949'):               # 읽기 함수 정의\n","  with open(filename, 'r', encoding=encoding) as f:\n","    data = [line.split('\\t') for line in f.read().splitlines()]\n","    data = data[1:]                                      # txt 파일의 헤더(id document label)는 제외하기\n","  return data\n","\n","def write_data(data, filename, encoding='cp949'):        # 쓰기 함수 정의\n","  with open(filename, 'w', encoding=encoding) as f:\n","    f.write(data)\n","\n","data = read_data('ratings_morphed.txt', encoding='cp949')\n","\n","print(len(data))\n","print(len(data[0])) \n","print(data[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esPQz5qo-XOS"},"source":["# 훈련데이터와 테스트데이터 분리 (자동)\n","data_text = [line[1] for line in data]      \t\t# 데이터 본문\n","data_senti = [line[2] for line in data]     \t\t# 데이터 긍부정 부분\n","\n","from sklearn.model_selection import train_test_split\n","train_data_text, test_data_text, train_data_senti, test_data_senti = train_test_split(data_text, data_senti, stratify=data_senti)\n","\n","# Counter 클래스를 이용해 각 분류가 훈련데이터와 테스트데이터에 같은 비율로 들어갔는지 확인해 본다 \n","from collections import Counter\n","train_data_senti_freq = Counter(train_data_senti)\n","print('train_data_senti_freq:', train_data_senti_freq)\n","\n","test_data_senti_freq = Counter(test_data_senti)\n","print('test_data_senti_freq:', test_data_senti_freq)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaQuKY5j-Zak"},"source":["# 훈련데이터와 테스트데이터 분리 (수동)\n","import random\n","random.shuffle(data)                            \t\t# 랜덤하게 섞는다\n","\n","data_70 = int(len(data)*0.7)\t\t\t\t\t              # 전체 데이터 크기의 70% 숫자를 찾는다\n","train_data = data[:data_70] \t\t\t\t\t              # 앞에서 70% 부분을 잘라 훈련데이터로\n","test_data = data[data_70:] \t\t\t\t\t                # 그 뒷부분을 테스트데이터로\n","\n","print('train data length:', len(train_data))    \t\t# 138212\n","print('test data length:', len(test_data))      \t\t# 59235\n","\n","# 훈련데이터 요소 분리\n","train_data_text = [line[1] for line in train_data]      \t# 훈련데이터 본문\n","train_data_senti = [line[2] for line in train_data]     \t# 훈련데이터 긍부정 부분\n","\n","# 테스트데이터 요소 분리\n","test_data_text = [line[1] for line in test_data]        \t# 테스트데이터 본문\n","test_data_senti = [line[2] for line in test_data]       \t# 테스트데이터 긍부정 부분"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o88BOJOk-akk"},"source":["# 행렬 형태로 변환\n","from sklearn.feature_extraction.text import CountVectorizer\n","vect = CountVectorizer(min_df=5).fit(train_data_text)  # 빈도 5이상의 단어만 대상\n","X_train = vect.transform(train_data_text)\t\t           # 행렬 생성\n","print(\"X_train:\\n\", repr(X_train))\t\t\t               # 생성된 행렬 개요"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yW1SYgUr-b4U"},"source":["# 행렬 내용 관찰\n","feature_names = vect.get_feature_names()\n","print(\"특성 개수:\", len(feature_names))\n","print(\"처음 20개 특성:\\m\", feature_names[:20])\n","print(\"3000~5000까지의 특성:\\n\", feature_names[3000:5000])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4XBt_Pq-dkH"},"source":["# 머신러닝 알고리즘 적용\n","import pandas as pd\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","y_train = pd.Series(train_data_senti)\t# 리스트 형태를 종속변수가 될 수 있는 1차원 배열(Series)로 만든다\n","\n","lr = LogisticRegression(solver=\"liblinear\")\n","lr.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NpWUMi9S-esy"},"source":["X_test = vect.transform(test_data_text)\n","y_test = pd.Series(test_data_senti)\n","\n","print(\"테스트 데이터 점수:\", lr.score(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4mopAL-J-hha"},"source":["# 1개 데이터 예측 "]},{"cell_type":"code","metadata":{"id":"_yj-Z7J6-kZn"},"source":["# 형태소분석기 시작\n","import rhinoMorph\n","rn = rhinoMorph.startRhino()\n","\n","new_input = '즐거운 하루!'\n","inputdata = []\n","morphed_input = rhinoMorph.onlyMorph_list(rn, new_input, pos=['NNG', 'NNP', 'VV', 'VA', 'XR', 'IC', 'MM', 'MAG', 'MAJ'])\n","morphed_input = ' '.join(morphed_input) # ['즐겁', '하루＇]를 한 개 문자열로 변환\n","\n","inputdata.append(morphed_input)         # 분석 결과를 리스트로 만들기\n","print('input data:', inputdata)         # ['즐겁 하루']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqOYkMZn-mxF"},"source":["X_input = vect.transform(inputdata)\t    # 앞에서 만든 11445 컬럼의 행렬에 적용\n","result = lr.predict(X_input) \t          # 0은 부정,1은 긍정\n","\n","if result == \"0\":\n","  print(\"부정적인 글입니다\")\n","else:\n","  print(\"긍정적인 글입니다\")"],"execution_count":null,"outputs":[]}]}